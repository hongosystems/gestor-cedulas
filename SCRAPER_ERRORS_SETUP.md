# Sistema de Registro y Reintento de Errores del Scraper

Este sistema permite que el scraper registre d√≥nde fall√≥ y procese primero esos lugares al reejecutarse.

## üìã Pasos de Configuraci√≥n

### 1. Crear la tabla en Supabase

Ejecuta la migraci√≥n SQL en el SQL Editor de Supabase (proyecto pjn-scraper):

```sql
-- Crear tabla para registrar errores del scraper
CREATE TABLE IF NOT EXISTS scraper_errors (
    id BIGSERIAL PRIMARY KEY,
    page INTEGER NOT NULL,
    row INTEGER NOT NULL,
    expediente_key TEXT,
    error_type TEXT NOT NULL, -- 'timeout', 'navigation', 'read_error', 'reload_error', 'paginator_error'
    error_message TEXT,
    error_details JSONB,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    resolved_at TIMESTAMPTZ,
    resolved BOOLEAN DEFAULT FALSE,
    retry_count INTEGER DEFAULT 0,
    last_retry_at TIMESTAMPTZ,
    UNIQUE(page, row, error_type) -- Evitar duplicados del mismo error
);

-- √çndices para b√∫squedas r√°pidas
CREATE INDEX IF NOT EXISTS idx_scraper_errors_resolved ON scraper_errors(resolved, created_at);
CREATE INDEX IF NOT EXISTS idx_scraper_errors_page_row ON scraper_errors(page, row);
CREATE INDEX IF NOT EXISTS idx_scraper_errors_expediente ON scraper_errors(expediente_key) WHERE expediente_key IS NOT NULL;
```

### 2. Usar el nuevo script de Python

El nuevo script `pw_mirror_favorites_to_supabase_with_retry.py` tiene las siguientes mejoras:

- **Registra errores autom√°ticamente** cuando falla:
  - Timeouts al leer filas
  - Errores de navegaci√≥n
  - Errores al recargar favoritos
  - Errores del paginador
  - Errores de procesamiento

- **Procesa errores primero** al iniciar:
  - Al ejecutar el script, primero procesa todos los errores pendientes
  - Luego contin√∫a con el flujo normal desde donde qued√≥

- **Marca errores como resueltos** cuando se procesan exitosamente

## üöÄ Uso

### Ejecutar el scraper con reintento de errores:

```bash
cd c:\proyectos\pjn-scraper
python pw_mirror_favorites_to_supabase_with_retry.py
```

### Ver errores pendientes:

```bash
npm run view:scraper-errors
```

## üìä Tipos de Errores Registrados

- `timeout`: Timeout al leer una fila de favoritos
- `navigation`: No naveg√≥ al expediente despu√©s de hacer click
- `read_error`: Error al leer los campos de una fila
- `reload_error`: Error al recargar la p√°gina de favoritos
- `paginator_error`: Error al hacer click en el n√∫mero de p√°gina
- `processing`: Error al procesar el expediente

## üîÑ Flujo de Reintento

1. **Al iniciar el scraper:**
   - Lee todos los errores pendientes (`resolved = false`)
   - Los procesa primero, en orden de creaci√≥n
   - Marca como resueltos los que se procesan exitosamente
   - Incrementa el contador de reintentos para los que fallan nuevamente

2. **Durante la ejecuci√≥n normal:**
   - Si ocurre un error, lo registra en `scraper_errors`
   - Contin√∫a con el siguiente expediente
   - No detiene toda la ejecuci√≥n

3. **En la pr√≥xima ejecuci√≥n:**
   - Los errores registrados se procesan primero
   - Esto asegura que eventualmente todos los expedientes se procesen

## üí° Ventajas

- ‚úÖ No pierde expedientes por errores temporales
- ‚úÖ Reintenta autom√°ticamente en la pr√≥xima ejecuci√≥n
- ‚úÖ Prioriza los lugares donde fall√≥
- ‚úÖ Mantiene un historial de errores para an√°lisis
- ‚úÖ No requiere intervenci√≥n manual para reintentar
